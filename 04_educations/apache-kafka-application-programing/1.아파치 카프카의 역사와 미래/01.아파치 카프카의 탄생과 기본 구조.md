# 아파치 카프카의 탄생과 기본 구조

## 카프카의 탄생

`링크드인` 에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는데 어려움
- 소스 애플리케이션 : 데이터를 생성하고 적재하기 위해서는 데이터를 생성
- 타겟 애플리케이션 : 데이터가 최종 적재
- 초기 운영 시, 단방향 통신을 통해 단순한 소스와 타겟이 연동
- 아키텍쳐가 점점 거대해지면서 데이터를 전송하는 라인이 기하급수적으로 복잡해지기 시작함

이를 해결하기 위한 방법
- 기존에 나와 있던 각종 상용 데이터 프레임워크와 오픈소스를 아키텍처에 녹여내어 데이터 파이프라인의 파편화 개선 노력
- 파편화된 데이터 파이프라인의 복잡도를 낮춰주는 아키텍처가 되지는 못함
- `링크드인` 의 데이터팀은 신규시스템은 만들기로 결정 -> 아프치 카프카 탄생
- 카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화

## 메시지 큐 구조를 그대로 살린 카프카 내부 구조

- 1:1 매칭의 문제점
  - 커플링으로 인해 한쪽의 이슈가 다른 한쪽의 애플리케이션에 영향을 미치게 했음
- 카프카는 이러한 의존도를 해결
  - 소스 애플리케이션에서 생성되는 데이터는 어느 타겟 애플리케이션으로 보낼 것인지 고민하지 않고 카프카로 넣으면 됨
- 카프카 내부에 데이터 저장은 `FIFO` (First In First Out) 방식
- 데이터를 보내는 곳이 `프로듀서`, 데이터를 가져가는 것이 `컨슈머`
- 데이터는 파티션 중 하나에서 저장, 모든 파티션에 동일하게 저장되는 것이 아님
- 데이터를 가져가도 삭제되지 않음
