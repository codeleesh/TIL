# 빅데이터 플랫폼 아키텍처와 카프카

## 초기 빅데이터 플랫폼

- 엔드 투 엔드로 각 서비스 애플리케이션으로부터 데이터를 배치로 모았는데 이러한 구조는 유연하지 못하였을뿐 아니라 실시간으로 생성되는 데이터들에 대한 인사이트를 서비스 애플리케이션에 빠르게 전달하지 못하는 단점이 있었습니다.
- 원천 데이터로부터 파생된 데이터의 히스토리를 파악하기가 어려웠고 계속 되는 데이터의 가공으로 인하여 데이터가 파편화되면서 데이터 거버넌스를 지키기 어려웠습니다.

이러한 문제점을 해결하기 위해서 나온 것이 람다 아키텍처입니다.

## 람다 아키텍처

람다 아키텍처는 3가지의 레이어로 나뉘게 됩니다.
- 배치 레이어, 서빙 레이어, 스피드 레이어
- 베치 레이어
  - 배치 데이터를 모아서 특정 시간, 타이밍마다 일괄 처리합니다.
  - 스파크 잡과 같은 대규모 배치 잡이 이 레이어에서 돌아가게 됩니다.
- 서빙 레이어
  - 가공된 데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간입니다.
  - 하둡이 대표적인 서빙 레이어 시스템 중 하나로 볼 수 있습니다.
  - 엄청나게 많은 대용량 데이터를 안정적으로 저장하는 것입니다.
- 스피드 레이어
  - 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도로 사용됩니다.
  - 배치 데이터에 비해 낮은 지연으로 분석이 필요한 경우에는 스피드 레이어를 통해 데이터를 분석하는데 보통 카프카와 같은 이벤트 스트리핑 플랫폼이 스피드 레이어에 위치하게 됩니다.

### 람다 아키텍처의 한계점

데이터를 배치 처리하는 레이어와 실시간 처리하는 레이어를 분리한 람다 아키텍처는 데이터 처리 방식을 명확히 나눌 수 있었지만 레이어가 2개로 나뉘기 때문에 생기는 단점들이 존재합니다.
- 레이어가 2개로 나뉘기 때문에 필요한 로직이 2벌이 필요합니다.
- 배치 데이터와 실시간 데이터를 융합하여 처리할때는 다소 유연하지 못한 파이프라인을 생성해야 한다는 점입니다.

## 카파 아키텍처

람다 아키텍처에서 단점으로 부각되었던 로직의 파편화, 디버깅, 배포, 운영 분리에 대한 이슈를 제거하기 위해 배치 레이어를 제거하는 방향을 고려하였습니다. 결국 카파 아키텍처는 스피드 레이어에서 데이터를 모두 처리할 수 있었으므로 엔지니어들은 더욱 효율적으로 개발과 운영에 임할 수 있었습니다.

## 스트리밍 데이터 레이크

카파 아키텍체에서 서빙 레이어를 제거한 아키텍처인 스트리밍 데이터 레이크를 제안하였습니다. 
