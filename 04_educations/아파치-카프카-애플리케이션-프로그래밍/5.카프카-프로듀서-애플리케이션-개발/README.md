# 카프카 프로듀서 애플리케이션 개발

## 카프카 프로듀서 소개

- 데이터의 시작점
- 카프카에 필요한 데이터를 선언
- 브로커의 특정 토픽의 파티션에 전송
- 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신
- 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

> Q. 자바가 아닌 언어로 구현하였을때 문제점?
> A. 아파치 카프카는 공식적으로 자바만 제공한다.

### 리더 파티션

- 프로듀서가 보낸 데이터를 저장하는 역할

### 팔로워 파티션

- 리더의 있는 데이터를 보고 복제하는 역할

### 배치 생성 단계

## 프로듀서 내부 구조

- ProducerRecord
  - 프로듀서에서 생성하는 레코드, 오프셋은 미포함
  - 포함되는 속성은 다음과 같음
    - 토픽
    - 파티션
    - 타임스탬프
    - 메시지 키
    - 메시지 값
- send()
  - 레코드를 전송 요청 메서드
  - send를 요청한다고 바로 보내지는 않음
- Partitioner
  - 어느 파티션으로 전송할지 지정하는 파티션
  - 기본값으로 DefaultPartitioner로 설정됨
- Accumulator
  - 배치로 묶어 전송할 데이터를 모으는 버퍼
  - 왜 할까?
    - send로 할때마다 항상 보내는 것이 아니라 배치로 묶어서 한번에 많은 데이터를 묶을 수 있음
    - 데이터 처리량이 많을 경우에 유리

## 파티셔너

### 프로듀서API 사용

- `UniformStickyPartitioner`, `RoundRobinPartitioner` 2개 파티셔너 제공
- 카프카 클라이언트 라이브러리 2.5.0 버전에서 파티셔너를 지정하지 않은 경우 `UniformStickyPartitioner`가 파티셔너로 기본 설정

### 메시지 키가 있을 경우 동작

- `UniformStickyPartitioner`, `RoundRobinPartitioner` 둘 다 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 레코드 전송
- 동일한 메시지 키가 존재하는 레코드는 동일한 파티션 번호에 전달됨
- 만약 파티션 개수가 변경될 경우 메시지 키와 파티션 번호 매칭은 깨지게 됨

#### 파티션 개수 변경

Producer와 Consumer가 처리해야할 양을 판단하여 카프카 파티션 개수를 증량한다.

- 파티션 개수만큼 Consumer 개수를 증량해야 한다.
- 파티션 개수를 충분히 큰 갯수로 운영하는 것이 중요하다.
- Producer가 보내는 데이터가 많아질 수 있기 때문에 충분한 갯수를 확보하는 것이 중요하다.
  - 예를 들어, 초당 10개씩 보낸다면 파티션의 갯수를 50, 100개로 운영
  - 파티션 개수를 변경하는 일이 거의 없음

### 메시지 키가 없을 때 동작

- 메시지 키가 없을 때는 파티션에 최대한 동일하게 분배하는 로직이 들어 있는데, `UniformStickyPartitioner`는 `RoundRobinPartitioner`의 단점을 개선하였다는 점이 다르다.

#### RoundRobinPartitioner

- ProducerRecord가 들어오는 대로 파티션을 순회하면서 전송
- Accumulator에서 묶이는 정도가 적기 때문에 전송 성능이 낮음

#### UniformStickyPartitioner

- Accumulator에서 레코드들이 배치로 묶일 때까지 기다렸다가 전송
- 배치로 묶일 뿐 결국 파티션을 순회하면서 보내기 때문에 모든 파티션에 분배되어 전송됨
- RoundRobinPartitioner에 비해 향상된 성능을 가짐

### 커스텀 파티셔너

- 카프카 클라이언트 라이브러리에서는 사용자 지정 파티셔너를 생성하기 위한 Partitioner 인터페이스를 제공한다.
- Partitioner 인터페이스를 상속받은 사용자 정의 클래스에서 메시지 키 또는 메시지 값에 따른 Partition 지정 로직을 적용한다.
- Partitioner를 통해 Partition이 지정된 데이터는 Accumulator에 버퍼로 쌓인다.
- Sender 스레드는 Accumulator에 쌓인 배치 데이터를 가져가 카프카 브로커로 전송한다.

#### 활용방안

예를 들어, 파티션으로 레코드를 보낼 때,

- 메시지 키가 있는 경우
  - UniformStickyPartitioner
- 메시지 키가 없는 경우
  - RoundRobinPartitioner

커스텀 파티션을 개발해서 사용한다면,

- Message Key 및 Value 를 몇 번째 파티션으로 지정해서 보낼 수 있다.

## 프로듀서 주요 옵션 소개

### 필수 옵션

아래 옵션은 필수 옵션이기 때문에 하나라도 넣지 않는다면 실행이 되지 않는다.

- bootstrap.servers
  - 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름:포트를 1개 이상 작성한다.
  - 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데에 이슈가 없도록 설정 가능하다.
- key.serializer
  - 레코드의 메시지 키를 직렬화하는 클래스를 지정한다.
- value.serializer
  - 레코드의 메시지 값을 직렬화하는 클래스를 지정한다.

프로듀서에서는 모든 레코드를 보낼때는 직렬화를 해서 브로커로 전송한다.
컨슈머에서는 직렬화된 데이터를 역직렬화 한다.
프로듀서가 보낸 데이터와 컨슈머에서 받는 데이터는 서로 알고 있어야 한다.

- 어떻게 직렬화할지 정해야 한다.
- 예를 들어, String으로 한다.
- float, int 등을 무조건 String으로 한다?

String Serializer로 하지 않았을때 문제점

- kafka-console-consumer 데이터로 보지 못할때는 String이 아닌 다른 방식으로 직렬화할때
  - 실제 운영 시 가능하면 String으로 직렬화한다.
- 프로듀서에서 보낸 데이터가 topic에 들어가면 어떻게 직렬화되었는지 모른다.
  - 컨슈머에서 역직렬화 로직을 넣어야하고 데이터를 역직렬화 시 해당 로직이 정상적으로 안될 수도 있음

### 선택 옵션

- acks
  - 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부를 확인하는 데에 사용하는 옵션
  - 0, 1, -1(all) 중 하나로 설정할 수 있다.
  - 기본 값은 1이다.
- linger.ms
  - 배치를 전송하기 전까지 기다리는 최소 시간이다.
  - send 메소드를 통해서 브로커를 통해 전송 시 Accumulator에서 모아서 전송
  - 10 -> 0.01, 100 -> 0.1
  - 기본값은 0이다.
- retries
  - 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수를 지정한다.
  - 기본값은 2147483647이다.
- max.in.flight.requests.per.connection
  - 한 번에 요청하는 최대 커넥션 개수
  - 설정된 값만큼 동시에 전달 요청을 수행
  - 기본값은 5이다.
- partitioner.class
  - 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정
  - 기본값은 org.apache.kafka.clients.producer.internals.DefaultPartitioner이다.
- enable.idempotence
  - 멱등성 프로듀서로 동작할지 여부를 설정
  - 기본값은 false이다.
- transactional.id
  - 프로듀서가 레도크를 전송할 때 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다.
  


