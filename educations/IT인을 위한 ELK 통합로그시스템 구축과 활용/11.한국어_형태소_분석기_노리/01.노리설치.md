# 노리에 대하여

## 노리 설치하기

### Elasticsearch Shell 접속

```bash
docker exec -it docker-elk_elasticsearch_1 /bin/bash
```

### elasticsearch-plugin 검색

```bash
find / -name elasticsearch-plugin
```

### 설치된 plugin 조회

```bash
docker exec -it docker-elk_elasticsearch_1 /usr/share/elasticsearch/bin/elasticsearch-plugin list
```

### plugin 설치 - 한글 형태소 분석기 노리

```bash
docker exec -it docker-elk_elasticsearch_1 /usr/share/elasticsearch/bin/elasticsearch-plugin install
```

### 설치 후 elasticsearch 재시작

```bash
docker restart docker-elk_elasticsearch_1
```

### 설치된 plugin 다시 조회

```bash
find / -name elasticsearch-plugin
```

## 노리 형태소 분석해보기

- 요청
```
POST _analyze
{
  "analyzer" : "nori",
  "text" : "검암역 주변에는 맛있는 곳이 많아요."
}
```

- 응답
```
{
  "tokens" : [
    {
      "token" : "검암",
      "start_offset" : 0,
      "end_offset" : 2,
      "type" : "word",
      "position" : 0
    },
    {
      "token" : "역",
      "start_offset" : 2,
      "end_offset" : 3,
      "type" : "word",
      "position" : 1
    },
    {
      "token" : "주변",
      "start_offset" : 4,
      "end_offset" : 6,
      "type" : "word",
      "position" : 2
    },
    {
      "token" : "맛있",
      "start_offset" : 9,
      "end_offset" : 11,
      "type" : "word",
      "position" : 5
    },
    {
      "token" : "곳",
      "start_offset" : 13,
      "end_offset" : 14,
      "type" : "word",
      "position" : 7
    },
    {
      "token" : "많",
      "start_offset" : 16,
      "end_offset" : 17,
      "type" : "word",
      "position" : 9
    }
  ]
}
```

## 노리 토크나이저와 토큰 필터

- 노리는 하나의 토크나이저와 두 개의 토큰 필터로 구성됨
  - nori_tokenizer : 토크나이저 (공백, 문자, 구두점 등을 사용)
  - nori_part_of_speech : 토큰필터
  - nori_readingform : 토큰필터
- 토크나이저 : 단어를 분리
- 토큰 필터 : 단어들을 검색 가능 하도록 가공
- 토크나이저 + 토큰 필터 -> 분석기(Analyzer) 한국어의 풀텍스트 서치 가능

### 노리 토크나이저

- decompound_mode: 토크나이저가 복합 토큰을 처리하는 방법을 결정
  - none : 데이터 그대로 유지 ex) 가거도 항, 가곡 역
  - discard : 원래 형태를 버림 ex) 가곡 역 => 가곡, 역
  - mixed : 분해도 하고 원래 형태를 유지 ex) 가곡 역 => 가곡 역, 가곡, 역
- user_dictionary
  - Nori 토크나이저는 기본적으로 mecab-ko-dic 사전을 사용
  - 사용자 지정 명사 (NNG)가 있는 user_dictionary가 기본 사전에 추가 가능
  - 사전은 다음 형식이어야 합니다. -> <토큰> [<토큰1> ... <토큰 n>]

### 노리 기능을 커스터마이징 사용

- 사전 파일 생성 - userdict_test.txt
```text
안녕하세요 안녕 하세 요
퐁당입니다 퐁당 입니다
```

- 사전 파일 배치
```bash
docker cp userdict_text.txt docker-elk_elasticsearch_1:/usr/share/elasticsearch/config
```

- 가장 먼저 인덱스가 노리의 분석 기능을 사용할 수 있도록 설정이 필요
```
PUT korean_analyzer1
{
  "settings": {
    "analysis": {
      "tokenizer":{
        "korean_nori_tokenizer":{
          "type":"nori_tokenizer",
          "decompound_mode":"mixed",
          "user_dictionary":"userdict_test.txt"
        }
      },
      "analyzer":{
        "nori_analyzer":{
          "type":"custom",
          "tokenizer":"korean_nori_tokenizer"
        }
      }
    }
  }
}
```

```
POST korean_analyzer1/_analyze
{
  "analyzer":"nori_analyzer",
  "text":"안녕하세요. 퐁당입니다."
}
```

### 토큰 필터(nori_part_of_speech)

- nori_part_of_speech 토큰 필터는 품사 태그 세트와 일치하는 토큰을 제거
